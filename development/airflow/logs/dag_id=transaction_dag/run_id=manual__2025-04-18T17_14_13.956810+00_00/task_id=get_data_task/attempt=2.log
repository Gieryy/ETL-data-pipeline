[2025-04-18T17:14:45.161+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-18T17:14:45.190+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: transaction_dag.get_data_task manual__2025-04-18T17:14:13.956810+00:00 [queued]>
[2025-04-18T17:14:45.202+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: transaction_dag.get_data_task manual__2025-04-18T17:14:13.956810+00:00 [queued]>
[2025-04-18T17:14:45.202+0000] {taskinstance.py:2867} INFO - Starting attempt 2 of 2
[2025-04-18T17:14:45.221+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): get_data_task> on 2025-04-18 17:14:13.956810+00:00
[2025-04-18T17:14:45.229+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=271) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-18T17:14:45.231+0000] {standard_task_runner.py:72} INFO - Started process 272 to run task
[2025-04-18T17:14:45.231+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'transaction_dag', 'get_data_task', 'manual__2025-04-18T17:14:13.956810+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/transaction_dag.py', '--cfg-path', '/tmp/tmp619cq4a2']
[2025-04-18T17:14:45.232+0000] {standard_task_runner.py:105} INFO - Job 7: Subtask get_data_task
[2025-04-18T17:14:45.279+0000] {task_command.py:467} INFO - Running <TaskInstance: transaction_dag.get_data_task manual__2025-04-18T17:14:13.956810+00:00 [running]> on host 317bb80a77ef
[2025-04-18T17:14:45.366+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='transaction_dag' AIRFLOW_CTX_TASK_ID='get_data_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-18T17:14:13.956810+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-04-18T17:14:13.956810+00:00'
[2025-04-18T17:14:45.368+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-18T17:14:45.422+0000] {logging_mixin.py:190} INFO - Data fetched from customers table: [('C1', 'Michelle Garcia', 'Female', 30, 'DI Yogyakarta', 'Yogyakarta'), ('C2', 'Timothy Matthews', 'Male', 63, 'Banten', 'Pandeglang'), ('C3', 'Judy Bailey', 'Female', 18, 'Jawa Barat', 'Tasikmalaya'), ('C4', 'Rachel Houston', 'Female', 20, 'Jawa Barat', 'Sukabumi'), ('C5', 'Jessica Andrade', 'Male', 35, 'Jawa Barat', 'Ciamis')]
[2025-04-18T17:14:45.424+0000] {python.py:240} INFO - Done. Returned value was: [('C1', 'Michelle Garcia', 'Female', 30, 'DI Yogyakarta', 'Yogyakarta'), ('C2', 'Timothy Matthews', 'Male', 63, 'Banten', 'Pandeglang'), ('C3', 'Judy Bailey', 'Female', 18, 'Jawa Barat', 'Tasikmalaya'), ('C4', 'Rachel Houston', 'Female', 20, 'Jawa Barat', 'Sukabumi'), ('C5', 'Jessica Andrade', 'Male', 35, 'Jawa Barat', 'Ciamis')]
[2025-04-18T17:14:45.454+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-18T17:14:45.454+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=transaction_dag, task_id=get_data_task, run_id=manual__2025-04-18T17:14:13.956810+00:00, execution_date=20250418T171413, start_date=20250418T171445, end_date=20250418T171445
[2025-04-18T17:14:45.539+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-18T17:14:45.568+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-04-18T17:14:45.571+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
