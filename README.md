# ETL-data-pipeline
Developed an end-to-end ETL pipeline using Python, Apache Airflow, PostgreSQL, and Docker to simulate a complete retail data workflow. The system generates realistic synthetic datasets (customers, stores, products, orders, payments, and transactions) with Faker, ingests them into PostgreSQL using SQLAlchemy, and orchestrates through Airflow DAGs.
